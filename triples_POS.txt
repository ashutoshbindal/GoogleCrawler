.	.
.	.
.	.
.	.

MathWorks	NNP
Machine	NNP
Translation	NN
.	.

The	DT
automated	VBN
translation	NN
of	IN
this	DT
page	NN
is	VBZ
provided	VBN
by	IN
a	DT
general	JJ
purpose	NN
third	JJ
party	NN
translator	NN
tool	NN
.	.

MathWorks	NNP
does	VBZ
not	RB
warrant	NN
,	,
and	CC
disclaims	VBZ
all	DT
liability	NN
for	IN
,	,
the	DT
accuracy	NN
,	,
suitability	NN
,	,
or	CC
fitness	NN
for	IN
purpose	NN
of	IN
the	DT
translation	NN
.	.

The	DT
aim	NN
of	IN
supervised	VBN
,	,
machine	NN
learning	NN
is	VBZ
to	TO
build	VB
a	DT
model	NN
that	WDT
makes	VBZ
predictions	NNS
based	VBN
on	IN
evidence	NN
in	IN
the	DT
presence	NN
of	IN
uncertainty	NN
.	.

As	IN
adaptive	JJ
algorithms	NNS
identify	VBP
patterns	NNS
in	IN
data	NNS
,	,
a	DT
computer	NN
``	``
learns	VBZ
''	''
from	IN
the	DT
observations	NNS
.	.

When	WRB
exposed	VBN
to	TO
more	JJR
observations	NNS
,	,
the	DT
computer	NN
improves	VBZ
its	PRP$
predictive	JJ
performance	NN
.	.

Specifically	RB
,	,
a	DT
supervised	JJ
learning	NN
algorithm	NN
takes	VBZ
a	DT
known	JJ
set	NN
of	IN
input	NN
data	NNS
and	CC
known	JJ
responses	NNS
to	TO
the	DT
data	NNS
-LRB-	-LRB-
output	NN
-RRB-	-RRB-
,	,
and	CC
trains	NNS
a	DT
model	NN
to	TO
generate	VB
reasonable	JJ
predictions	NNS
for	IN
the	DT
response	NN
to	TO
new	JJ
data	NNS
.	.
.	.

For	IN
example	NN
,	,
suppose	VB
you	PRP
want	VBP
to	TO
predict	VB
whether	IN
someone	NN
will	MD
have	VB
a	DT
heart	NN
attack	NN
within	IN
a	DT
year	NN
.	.

You	PRP
have	VBP
a	DT
set	NN
of	IN
data	NNS
on	IN
previous	JJ
patients	NNS
,	,
including	VBG
age	NN
,	,
weight	NN
,	,
height	NN
,	,
blood	NN
pressure	NN
,	,
etc.	FW
.	.

You	PRP
know	VBP
whether	IN
the	DT
previous	JJ
patients	NNS
had	VBD
heart	NN
attacks	NNS
within	IN
a	DT
year	NN
of	IN
their	PRP$
measurements	NNS
.	.

So	RB
,	,
the	DT
problem	NN
is	VBZ
combining	VBG
all	PDT
the	DT
existing	VBG
data	NNS
into	IN
a	DT
model	NN
that	WDT
can	MD
predict	VB
whether	IN
a	DT
new	JJ
person	NN
will	MD
have	VB
a	DT
heart	NN
attack	NN
within	IN
a	DT
year	NN
.	.

You	PRP
can	MD
think	VB
of	IN
the	DT
entire	JJ
set	NN
of	IN
input	NN
data	NNS
as	IN
a	DT
heterogeneous	JJ
matrix	NN
.	.

Rows	NNS
of	IN
the	DT
matrix	NN
are	VBP
called	VBN
observations	NNS
,	,
examples	NNS
,	,
or	CC
instances	NNS
,	,
and	CC
each	DT
contain	VBP
a	DT
set	NN
of	IN
measurements	NNS
for	IN
a	DT
subject	NN
-LRB-	-LRB-
patients	NNS
in	IN
the	DT
example	NN
-RRB-	-RRB-
.	.

Columns	NNS
of	IN
the	DT
matrix	NN
are	VBP
called	VBN
predictors	NNS
,	,
attributes	NNS
,	,
or	CC
features	NNS
,	,
and	CC
each	DT
are	VBP
variables	NNS
representing	VBG
a	DT
measurement	NN
taken	VBN
on	IN
every	DT
subject	NN
-LRB-	-LRB-
age	NN
,	,
weight	NN
,	,
height	NN
,	,
etc.	FW
.	.

in	IN
the	DT
example	NN
-RRB-	-RRB-
.	.

You	PRP
can	MD
think	VB
of	IN
the	DT
response	NN
data	NNS
as	IN
a	DT
column	NN
vector	NN
where	WRB
each	DT
row	NN
contains	VBZ
the	DT
output	NN
of	IN
the	DT
corresponding	JJ
observation	NN
in	IN
the	DT
input	NN
data	NNS
-LRB-	-LRB-
whether	IN
the	DT
patient	NN
had	VBD
a	DT
heart	NN
attack	NN
-RRB-	-RRB-
.	.

To	TO
fit	VB
or	CC
train	VB
a	DT
supervised	JJ
learning	NN
model	NN
,	,
choose	VB
an	DT
appropriate	JJ
algorithm	NN
,	,
and	CC
then	RB
pass	VB
the	DT
input	NN
and	CC
response	NN
data	NNS
to	TO
it	PRP
.	.

Supervised	VBN
learning	VBG
splits	VBZ
into	IN
two	CD
broad	JJ
categories	NNS
:	:
classification	NN
and	CC
regression	NN
.	.

In	IN
classification	NN
,	,
the	DT
goal	NN
is	VBZ
to	TO
assign	VB
a	DT
class	NN
-LRB-	-LRB-
or	CC
label	NN
-RRB-	-RRB-
from	IN
a	DT
finite	JJ
set	NN
of	IN
classes	NNS
to	TO
an	DT
observation	NN
.	.

That	DT
is	VBZ
,	,
responses	NNS
are	VBP
categorical	JJ
variables	NNS
.	.

Applications	NNS
include	VBP
spam	NN
filters	NNS
,	,
advertisement	NN
recommendation	NN
systems	NNS
,	,
and	CC
image	NN
and	CC
speech	NN
recognition	NN
.	.

Predicting	VBG
whether	IN
a	DT
patient	NN
will	MD
have	VB
a	DT
heart	NN
attack	NN
within	IN
a	DT
year	NN
is	VBZ
a	DT
classification	NN
problem	NN
,	,
and	CC
the	DT
possible	JJ
classes	NNS
are	VBP
true	JJ
and	CC
false	JJ
.	.

Classification	NN
algorithms	NNS
usually	RB
apply	VBP
to	TO
nominal	JJ
response	NN
values	NNS
.	.

However	RB
,	,
some	DT
algorithms	NNS
can	MD
accommodate	VB
ordinal	JJ
classes	NNS
-LRB-	-LRB-
see	VB
fitcecoc	NN
-RRB-	-RRB-
.	.
.	.

In	IN
regression	NN
,	,
the	DT
goal	NN
is	VBZ
to	TO
predict	VB
a	DT
continuous	JJ
measurement	NN
for	IN
an	DT
observation	NN
.	.

That	DT
is	VBZ
,	,
the	DT
responses	NNS
variables	NNS
are	VBP
real	JJ
numbers	NNS
.	.

Applications	NNS
include	VBP
forecasting	NN
stock	NN
prices	NNS
,	,
energy	NN
consumption	NN
,	,
or	CC
disease	NN
incidence	NN
.	.

Statistics	NNPS
and	CC
Machine	NNP
Learning	NNP
Toolbox	NNP
â„¢	NN
supervised	VBD
learning	VBG
functionalities	NNS
comprise	VBP
a	DT
stream-lined	JJ
,	,
object	NN
framework	NN
.	.

You	PRP
can	MD
efficiently	RB
train	VB
a	DT
variety	NN
of	IN
algorithms	NNS
,	,
combine	VBP
models	NNS
into	IN
an	DT
ensemble	NN
,	,
assess	VB
model	NN
performances	NNS
,	,
cross-validate	NN
,	,
and	CC
predict	VBP
responses	NNS
for	IN
new	JJ
data	NNS
.	.

While	IN
there	EX
are	VBP
many	JJ
Statistics	NNPS
and	CC
Machine	NNP
Learning	NNP
Toolbox	NNP
algorithms	NNS
for	IN
supervised	JJ
learning	NN
,	,
most	JJS
use	VBP
the	DT
same	JJ
basic	JJ
workflow	NN
for	IN
obtaining	VBG
a	DT
predictor	NN
model	NN
.	.

-LRB-	-LRB-
Detailed	JJ
instruction	NN
on	IN
the	DT
steps	NNS
for	IN
ensemble	NN
learning	NN
is	VBZ
in	IN
Framework	NNP
for	IN
Ensemble	NNP
Learning	NNP
.	.
-RRB-	-RRB-

The	DT
steps	NNS
for	IN
supervised	JJ
learning	NN
are	VBP
:	:
.	.

Prepare	VB
Data	NNS
.	.

Choose	VB
an	DT
Algorithm	NN
.	.

Fit	VB
a	DT
Model	NNP
.	.

Choose	VB
a	DT
Validation	NNP
Method	NNP
.	.

Examine	VB
Fit	NN
and	CC
Update	NNP
Until	IN
Satisfied	NNP
.	.

Use	NNP
Fitted	NNP
Model	NNP
for	IN
Predictions	NNS
.	.

All	DT
supervised	JJ
learning	NN
methods	NNS
start	VBP
with	IN
an	DT
input	NN
data	NNS
matrix	NN
,	,
usually	RB
called	VBN
X	NN
here	RB
.	.

Each	DT
row	NN
of	IN
X	NN
represents	VBZ
one	CD
observation	NN
.	.

Each	DT
column	NN
of	IN
X	NN
represents	VBZ
one	CD
variable	NN
,	,
or	CC
predictor	NN
.	.

Represent	JJ
missing	VBG
entries	NNS
with	IN
NaN	NN
values	NNS
in	IN
X.	NNP
Statistics	NNPS
and	CC
Machine	NNP
Learning	NNP
Toolbox	NNP
supervised	VBD
learning	VBG
algorithms	NNS
can	MD
handle	VB
NaN	NNP
values	NNS
,	,
either	CC
by	IN
ignoring	VBG
them	PRP
or	CC
by	IN
ignoring	VBG
any	DT
row	NN
with	IN
a	DT
NaN	NN
value	NN
.	.

You	PRP
can	MD
use	VB
various	JJ
data	NNS
types	NNS
for	IN
response	NN
data	NNS
Y.	NNP
Each	DT
element	NN
in	IN
Y	NN
represents	VBZ
the	DT
response	NN
to	TO
the	DT
corresponding	JJ
row	NN
of	IN
X.	NNP
Observations	NNS
with	IN
missing	VBG
Y	NN
data	NNS
are	VBP
ignored	VBN
.	.

For	IN
regression	NN
,	,
Y	NN
must	MD
be	VB
a	DT
numeric	JJ
vector	NN
with	IN
the	DT
same	JJ
number	NN
of	IN
elements	NNS
as	IN
the	DT
number	NN
of	IN
rows	NNS
of	IN
X.	NNP
For	IN
classification	NN
,	,
Y	NN
can	MD
be	VB
any	DT
of	IN
these	DT
data	NNS
types	NNS
.	.

This	DT
table	NN
also	RB
contains	VBZ
the	DT
method	NN
of	IN
including	VBG
missing	VBG
entries	NNS
.	.
.	.

There	EX
are	VBP
tradeoffs	NNS
between	IN
several	JJ
characteristics	NNS
of	IN
algorithms	NNS
,	,
such	JJ
as	IN
:	:
.	.

Speed	NN
of	IN
training	NN
.	.

Memory	NN
usage	NN
.	.

Predictive	JJ
accuracy	NN
on	IN
new	JJ
data	NNS
.	.

Transparency	NN
or	CC
interpretability	NN
,	,
meaning	VBG
how	WRB
easily	RB
you	PRP
can	MD
understand	VB
the	DT
reasons	NNS
an	DT
algorithm	NN
makes	VBZ
its	PRP$
predictions	NNS
.	.

Details	NNS
of	IN
the	DT
algorithms	NNS
appear	VBP
in	IN
Characteristics	NNS
of	IN
Classification	NN
Algorithms	NNS
.	.

More	JJR
detail	NN
about	IN
ensemble	NN
algorithms	NNS
is	VBZ
in	IN
Choose	VB
an	DT
Applicable	JJ
Ensemble	NN
Method	NN
.	.

The	DT
fitting	JJ
function	NN
you	PRP
use	VBP
depends	VBZ
on	IN
the	DT
algorithm	NN
you	PRP
choose	VBP
.	.
.	.

For	IN
a	DT
comparison	NN
of	IN
these	DT
algorithms	NNS
,	,
see	VBP
Characteristics	NNS
of	IN
Classification	NN
Algorithms	NNS
.	.

The	DT
three	CD
main	JJ
methods	NNS
to	TO
examine	VB
the	DT
accuracy	NN
of	IN
the	DT
resulting	VBG
fitted	JJ
model	NN
are	VBP
:	:
.	.

Examine	VB
the	DT
resubstitution	NN
error	NN
.	.

For	IN
examples	NNS
,	,
see	VB
:	:
.	.

Classification	NN
Tree	NN
Resubstitution	NN
Error	NN
.	.

Cross	NNP
Validate	NNP
a	DT
Regression	NN
Tree	NN
.	.

Test	NN
Ensemble	NN
Quality	NNP
.	.

Example	NN
:	:
Resubstitution	NNP
Error	NNP
of	IN
a	DT
Discriminant	JJ
Analysis	NN
Classifier	NN
.	.

Examine	VB
the	DT
cross-validation	NN
error	NN
.	.

For	IN
examples	NNS
,	,
see	VB
:	:
.	.

Cross	NNP
Validate	NNP
a	DT
Regression	NN
Tree	NN
.	.

Test	NN
Ensemble	NN
Quality	NNP
.	.

Classification	NN
with	IN
Many	JJ
Categorical	JJ
Levels	NNS
.	.

Cross	NNP
Validating	VBG
a	DT
Discriminant	JJ
Analysis	NN
Classifier	NN
.	.

Examine	VB
the	DT
out-of-bag	NN
error	NN
for	IN
bagged	JJ
decision	NN
trees	NNS
.	.

For	IN
examples	NNS
,	,
see	VB
:	:
.	.

Test	NN
Ensemble	NN
Quality	NNP
.	.

Regression	NN
of	IN
Insurance	NN
Risk	NN
Rating	NNP
for	IN
Car	NNP
Imports	NNS
Using	VBG
TreeBagger	NN
.	.

Classifying	VBG
Radar	NN
Returns	NNS
for	IN
Ionosphere	NNP
Data	NNP
Using	VBG
TreeBagger	NNP
.	.

After	IN
validating	VBG
the	DT
model	NN
,	,
you	PRP
might	MD
want	VB
to	TO
change	VB
it	PRP
for	IN
better	JJR
accuracy	NN
,	,
better	JJR
speed	NN
,	,
or	CC
to	TO
use	VB
less	JJR
memory	NN
.	.

Change	NNP
fitting	JJ
parameters	NNS
to	TO
try	VB
to	TO
get	VB
a	DT
more	RBR
accurate	JJ
model	NN
.	.

For	IN
examples	NNS
,	,
see	VB
:	:
.	.

Tune	VB
RobustBoost	NNP
.	.

Train	NN
Ensemble	NN
With	IN
Unequal	JJ
Classification	NN
Costs	NNS
.	.

Improve	VB
a	DT
Discriminant	JJ
Analysis	NN
Classifier	NN
.	.

Change	NNP
fitting	JJ
parameters	NNS
to	TO
try	VB
to	TO
get	VB
a	DT
smaller	JJR
model	NN
.	.

This	DT
sometimes	RB
gives	VBZ
a	DT
model	NN
with	IN
more	JJR
accuracy	NN
.	.

For	IN
examples	NNS
,	,
see	VB
:	:
.	.

Select	NNP
Appropriate	NNP
Tree	NNP
Depth	NNP
.	.

Prune	VB
a	DT
Classification	NN
Tree	NN
.	.

Surrogate	NN
Splits	VBZ
.	.

Regularize	VB
a	DT
Regression	NN
Ensemble	NN
.	.

Regression	NN
of	IN
Insurance	NN
Risk	NN
Rating	NNP
for	IN
Car	NNP
Imports	NNS
Using	VBG
TreeBagger	NN
.	.

Classifying	VBG
Radar	NN
Returns	NNS
for	IN
Ionosphere	NNP
Data	NNP
Using	VBG
TreeBagger	NNP
.	.

Try	VB
a	DT
different	JJ
algorithm	NN
.	.

For	IN
applicable	JJ
choices	NNS
,	,
see	VB
:	:
.	.

Characteristics	NNS
of	IN
Classification	NN
Algorithms	NNS
.	.

Choose	VB
an	DT
Applicable	JJ
Ensemble	NN
Method	NN
.	.

When	WRB
satisfied	VBN
with	IN
a	DT
model	NN
of	IN
some	DT
types	NNS
,	,
you	PRP
can	MD
trim	VB
it	PRP
using	VBG
the	DT
appropriate	JJ
compact	JJ
function	NN
-LRB-	-LRB-
compact	NN
for	IN
classification	NN
trees	NNS
,	,
compact	JJ
for	IN
regression	NN
trees	NNS
,	,
compact	JJ
for	IN
discriminant	JJ
analysis	NN
,	,
compact	JJ
for	IN
naive	JJ
Bayes	NNP
,	,
compact	JJ
for	IN
SVM	NNP
,	,
compact	JJ
for	IN
ECOC	NN
models	NNS
,	,
compact	JJ
for	IN
classification	NN
ensembles	NNS
,	,
and	CC
compact	JJ
for	IN
regression	NN
ensembles	NNS
-RRB-	-RRB-
.	.

compact	JJ
removes	VBZ
training	NN
data	NNS
and	CC
other	JJ
properties	NNS
not	RB
required	VBN
for	IN
prediction	NN
,	,
e.	FW
g.	FW
,	,
pruning	NN
information	NN
for	IN
decision	NN
trees	NNS
,	,
from	IN
the	DT
model	NN
to	TO
reduce	VB
memory	NN
consumption	NN
.	.

Because	IN
kNN	NN
classification	NN
models	NNS
require	VBP
all	DT
of	IN
the	DT
training	NN
data	NNS
to	TO
predict	VB
labels	NNS
,	,
you	PRP
can	MD
not	RB
reduce	VB
the	DT
size	NN
of	IN
a	DT
ClassificationKNN	NN
model	NN
.	.

To	TO
predict	VB
classification	NN
or	CC
regression	NN
response	NN
for	IN
most	JJS
fitted	JJ
models	NNS
,	,
use	VBP
the	DT
predict	VBP
method	NN
:	:
.	.

obj	NN
is	VBZ
the	DT
fitted	JJ
model	NN
or	CC
fitted	JJ
compact	JJ
model	NN
.	.

Xnew	NNP
is	VBZ
the	DT
new	JJ
input	NN
data	NNS
.	.

Ypredicted	NNP
is	VBZ
the	DT
predicted	VBN
response	NN
,	,
either	CC
classification	NN
or	CC
regression	NN
.	.

This	DT
table	NN
shows	VBZ
typical	JJ
characteristics	NNS
of	IN
the	DT
various	JJ
supervised	JJ
learning	NN
algorithms	NNS
.	.

The	DT
characteristics	NNS
in	IN
any	DT
particular	JJ
case	NN
can	MD
vary	VB
from	IN
the	DT
listed	VBN
ones	NNS
.	.

Use	VB
the	DT
table	NN
as	IN
a	DT
guide	NN
for	IN
your	PRP$
initial	JJ
choice	NN
of	IN
algorithms	NNS
.	.

Decide	VB
on	IN
the	DT
tradeoff	NN
you	PRP
want	VBP
in	IN
speed	NN
,	,
memory	NN
usage	NN
,	,
flexibility	NN
,	,
and	CC
interpretability	NN
.	.

Tip	NN
:	:
Try	VB
a	DT
decision	NN
tree	NN
or	CC
discriminant	JJ
first	RB
,	,
because	IN
these	DT
classifiers	NNS
are	VBP
fast	JJ
and	CC
easy	JJ
to	TO
interpret	VB
.	.

If	IN
the	DT
models	NNS
are	VBP
not	RB
accurate	JJ
enough	JJ
predicting	VBG
the	DT
response	NN
,	,
try	VB
other	JJ
classifiers	NNS
with	IN
higher	JJR
flexibility	NN
.	.

To	TO
control	VB
flexibility	NN
,	,
see	VB
the	DT
details	NNS
for	IN
each	DT
classifier	NN
type	NN
.	.

To	TO
avoid	VB
overfitting	NN
,	,
look	VB
for	IN
a	DT
model	NN
of	IN
lower	JJR
flexibility	NN
that	WDT
provides	VBZ
sufficient	JJ
accuracy	NN
.	.
.	.

The	DT
results	NNS
in	IN
this	DT
table	NN
are	VBP
based	VBN
on	IN
an	DT
analysis	NN
of	IN
many	JJ
data	NNS
sets	NNS
.	.

The	DT
data	NNS
sets	NNS
in	IN
the	DT
study	NN
have	VBP
up	RP
to	TO
7000	CD
observations	NNS
,	,
80	CD
predictors	NNS
,	,
and	CC
50	CD
classes	NNS
.	.

This	DT
list	NN
defines	VBZ
the	DT
terms	NNS
in	IN
the	DT
table	NN
.	.

Speed	NN
:	:
.	.

Fast	JJ
--	:
0	CD
.	.

01	NN
second	NN
.	.

Medium	NN
--	:
1	CD
second	NN
.	.

Slow	NNP
--	:
100	CD
seconds	NNS
.	.
.	.

Memory	NN
.	.

Small	JJ
--	:
1MB	NN
.	.

Medium	NN
--	:
4MB	NN
.	.

Large	JJ
--	:
100MB	NN
.	.

Note	VB
:	:
The	DT
table	NN
provides	VBZ
a	DT
general	JJ
guide	NN
.	.

Your	PRP$
results	NNS
depend	VBP
on	IN
your	PRP$
data	NNS
and	CC
the	DT
speed	NN
of	IN
your	PRP$
machine	NN
.	.

This	DT
table	NN
describes	VBZ
the	DT
data-type	JJ
support	NN
of	IN
predictors	NNS
for	IN
each	DT
classifier	NN
.	.
.	.

Choose	VB
your	PRP$
country	NN
to	TO
get	VB
translated	VBN
content	NN
where	WRB
available	JJ
and	CC
see	VB
local	JJ
events	NNS
and	CC
offers	NNS
.	.

Based	VBN
on	IN
your	PRP$
location	NN
,	,
we	PRP
recommend	VBP
that	IN
you	PRP
select	VBP
:	:
.	.

You	PRP
can	MD
also	RB
select	VB
a	DT
location	NN
from	IN
the	DT
following	VBG
list	NN
:	:
.	.

See	VB
all	DT
countries	NNS
.	.

Accelerating	VBG
the	DT
pace	NN
of	IN
engineering	NN
and	CC
science	NN
.	.

MathWorks	NNP
is	VBZ
the	DT
leading	VBG
developer	NN
of	IN
mathematical	JJ
computing	NN
software	NN
for	IN
engineers	NNS
and	CC
scientists	NNS
.	.

Discover	NNP
.	.

Â©	NN
1994-2017	CD
The	DT
MathWorks	NNPS
,	,
Inc.	NNP
.	.

Join	VB
the	DT
conversation	NN
.	.

The	DT
most	RBS
widely	RB
used	VBN
learning	VBG
algorithms	NNS
are	VBP
Support	NN
Vector	NNP
Machines	NNP
,	,
linear	JJ
regression	NN
,	,
logistic	JJ
regression	NN
,	,
naive	JJ
Bayes	NNP
,	,
linear	JJ
discriminant	JJ
analysis	NN
,	,
decision	NN
trees	NNS
,	,
k-nearest	NN
neighbor	NN
algorithm	NN
,	,
and	CC
Neural	NNP
Networks	NNP
-LRB-	-LRB-
Multilayer	JJ
perceptron	NN
-RRB-	-RRB-
.	.

Specifically	RB
,	,
a	DT
supervised	JJ
learning	NN
algorithm	NN
takes	VBZ
a	DT
known	JJ
set	NN
of	IN
input	NN
data	NNS
and	CC
known	JJ
responses	NNS
to	TO
the	DT
data	NNS
-LRB-	-LRB-
output	NN
-RRB-	-RRB-
,	,
and	CC
trains	NNS
a	DT
model	NN
to	TO
generate	VB
reasonable	JJ
predictions	NNS
for	IN
the	DT
response	NN
to	TO
new	JJ
data	NNS
.	.

Supervised	VBN
learning	NN
is	VBZ
a	DT
type	NN
of	IN
machine	NN
learning	NN
algorithm	NN
that	WDT
uses	VBZ
a	DT
known	JJ
dataset	NN
-LRB-	-LRB-
called	VBN
the	DT
training	NN
dataset	NN
-RRB-	-RRB-
to	TO
make	VB
predictions	NNS
.	.

The	DT
training	NN
dataset	NN
includes	VBZ
input	NN
data	NNS
and	CC
response	NN
values	NNS
.	.

From	IN
it	PRP
,	,
the	DT
supervised	JJ
learning	NN
algorithm	NN
seeks	VBZ
to	TO
build	VB
a	DT
model	NN
that	WDT
can	MD
make	VB
predictions	NNS
of	IN
the	DT
response	NN
values	NNS
for	IN
a	DT
new	JJ
dataset	NN
.	.

A	DT
test	NN
dataset	NN
is	VBZ
often	RB
used	VBN
to	TO
validate	VB
the	DT
model	NN
.	.

Using	VBG
larger	JJR
training	NN
datasets	NNS
often	RB
yield	VBP
models	NNS
with	IN
higher	JJR
predictive	JJ
power	NN
that	WDT
can	MD
generalize	VB
well	RB
for	IN
new	JJ
datasets	NNS
.	.

In	IN
the	DT
data	NNS
science	NN
course	NN
that	IN
I	PRP
instruct	VBP
,	,
we	PRP
cover	VBP
most	JJS
of	IN
the	DT
data	NNS
science	NN
pipeline	NN
but	CC
focus	NN
especially	RB
on	IN
machine	NN
learning	NN
.	.

Besides	IN
teaching	NN
model	NN
evaluation	NN
procedures	NNS
and	CC
metrics	NNS
,	,
we	PRP
obviously	RB
teach	VBP
the	DT
algorithms	NNS
themselves	PRP
,	,
primarily	RB
for	IN
supervised	JJ
learning	NN
.	.

Now	RB
your	PRP$
supervised	JJ
learning	NN
algorithm	NN
will	MD
try	VB
to	TO
learn	VB
the	DT
probability	NN
of	IN
Y	NN
for	IN
a	DT
particular	JJ
X	NN
.	.

In	IN
probability	NN
notation	NN
it	PRP
is	VBZ
called	VBN
posteriorly	JJ
probability	NN
or	CC
Probability	NN
-LRB-	-LRB-
Y/X	NN
-RRB-	-RRB-
.	.

